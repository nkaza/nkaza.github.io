<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.4.0 for Hugo" />
  

  
  









  




  
  

  
  
  

  
    <meta name="google-site-verification" content="qq9qzDEmo2CWQJ-GjKaptUQs7Odqb9aHsm4k_yFaVAQ" />
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Nikhil Kaza" />

  
  
  
    
  
  <meta name="description" content="Introduction Drone imagery offers promising capabilities for urban planning, but its application warrants a measured and critical perspective. While drones can rapidly capture high-resolution spatial data, enabling planners to visualize land use, infrastructure, and environmental conditions with impressive detail, their use also raises concerns about data accuracy, privacy, and long-term integration." />

  
  <link rel="alternate" hreflang="en-us" href="https://nkaza.github.io/post/working-with-drone-imagery/" />

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.f1ecf783c14edc00c9320c205831ad8e.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.0d287f18ae9831e05717a040ad587d40.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-121426944-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-121426944-1', { 'anonymize_ip': true });
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  

  

  




  
  
  

  

  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu1ca6a6912ef6c300619228a995d3f134_46128_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu1ca6a6912ef6c300619228a995d3f134_46128_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://nkaza.github.io/post/working-with-drone-imagery/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="Nikhil Kaza" />
  <meta property="og:url" content="https://nkaza.github.io/post/working-with-drone-imagery/" />
  <meta property="og:title" content="Working with Drone Imagery | Nikhil Kaza" />
  <meta property="og:description" content="Introduction Drone imagery offers promising capabilities for urban planning, but its application warrants a measured and critical perspective. While drones can rapidly capture high-resolution spatial data, enabling planners to visualize land use, infrastructure, and environmental conditions with impressive detail, their use also raises concerns about data accuracy, privacy, and long-term integration." /><meta property="og:image" content="https://nkaza.github.io/post/working-with-drone-imagery/featured.png" />
    <meta property="twitter:image" content="https://nkaza.github.io/post/working-with-drone-imagery/featured.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2025-09-04T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2025-09-04T16:09:37-04:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://nkaza.github.io/post/working-with-drone-imagery/"
  },
  "headline": "Working with Drone Imagery",
  
  "image": [
    "https://nkaza.github.io/post/working-with-drone-imagery/featured.png"
  ],
  
  "datePublished": "2025-09-04T00:00:00Z",
  "dateModified": "2025-09-04T16:09:37-04:00",
  
  "author": {
    "@type": "Person",
    "name": "Nikhil Kaza"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Nikhil Kaza",
    "logo": {
      "@type": "ImageObject",
      "url": "https://nkaza.github.io/media/icon_hu1ca6a6912ef6c300619228a995d3f134_46128_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Introduction Drone imagery offers promising capabilities for urban planning, but its application warrants a measured and critical perspective. While drones can rapidly capture high-resolution spatial data, enabling planners to visualize land use, infrastructure, and environmental conditions with impressive detail, their use also raises concerns about data accuracy, privacy, and long-term integration."
}
</script>

  

  

  
  
  
  
  
    <script src="https://cdn.jsdelivr.net/gh/osano/cookieconsent@3.1.1/build/cookieconsent.min.js" integrity="sha512-yXXqOFjdjHNH1GND+1EO0jbvvebABpzGKD66djnUfiKlYME5HGMUJHoCaeE4D5PTG2YsSJf6dwqyUUvQvS0vaA==" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/osano/cookieconsent@3.1.1/build/cookieconsent.min.css" integrity="sha512-LQ97camar/lOliT/MqjcQs5kWgy6Qz/cCRzzRzUCfv0fotsCTC9ZHXaPQmJV8Xu/PVALfJZ7BDezl5lW3/qBxg==" crossorigin="anonymous">
  
  <script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#1565c0",
          "text": "rgb(255, 255, 255)"
        },
        "button": {
          "background": "rgb(255, 255, 255)",
          "text": "#1565c0"
        }
      },
      "theme": "classic",
      "content": {
        "message": "Third party cookies are used on this website. You can disable them on your browser's privacy settings without losing any functionality.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "/privacy/"
      }
    })});
  </script>


  





  <title>Working with Drone Imagery | Nikhil Kaza</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="04819ec4ee2090dd14cd57056a1a009e" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.8f76bdc9e086322ed5147724ebba3d06.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Nikhil Kaza</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Nikhil Kaza</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#posts"><span>Posts</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#featured"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#teaching"><span>Teaching</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/files/pdfs/cv.pdf"><span>CV</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

          

          
          
          
            
              
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="https://cse.google.com/cse?cx=003304552390625136873:si-f1ne2ahe" target="_blank" rel="noopener"><span>Search</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        

        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    <article class="article">
  





















  
  


<div class="article-container pt-3">
  <h1>Working with Drone Imagery</h1>

  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
          Last updated on
      
    
    Sep 4, 2025
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    15 min read
  </span>
  

  
  
  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/new-urban-analytics/">new-urban-analytics</a></span>
  

</div>

  





</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 720px;">
  <div style="position: relative">
    <img src="/post/working-with-drone-imagery/featured_hu83ae8d634f78bc0357be55215d004b8f_2163713_720x2500_fit_q75_h2_lanczos_3.webp" width="720" height="720" alt="" class="featured-image">
    
  </div>
</div>


  <div class="article-container">
    <div class="row">
      <div class="col-12 col-lg-9 article-style">
        <h2 id="introduction">Introduction</h2>
<p>Drone imagery offers promising capabilities for urban planning, but its application warrants a measured and critical perspective. While drones can rapidly capture high-resolution spatial data, enabling planners to visualize land use, infrastructure, and environmental conditions with impressive detail, their use also raises concerns about data accuracy, privacy, and long-term integration. The quality of drone imagery can vary depending on weather, flight regulations, and operator expertise, potentially limiting its reliability for complex planning decisions. Moreover, the proliferation of aerial surveillance introduces ethical questions around consent and the monitoring of public and private spaces. Urban planners must also grapple with the challenge of incorporating drone data into existing workflows and regulatory frameworks, which are often not designed to accommodate such fast-evolving technologies. Nonetheless it is useful to figure out how to use them effectively.</p>
<p>When focusing specifically on drones, the types of data they can collect are largely determined by the onboard sensors they carry. Standard RGB cameras provide high-resolution visual imagery, useful for mapping, inspections, and photogrammetry. Multispectral sensors detect light across several bands, allowing analysis of vegetation health, water pollution, and urban heat islands—especially valuable in environmental planning. Thermal cameras capture infrared radiation, helping identify energy inefficiencies in buildings or monitor heat patterns in dense urban areas. LiDAR systems, which use laser pulses to measure distances, generate precise 3D models of terrain and infrastructure, even in areas with dense vegetation or poor lighting.</p>
<p>Within R, tools like <code>FIELDimageR</code> and <code>uasim</code> offer specialized functions for managing UAV imagery, including organizing flight data, converting formats, and preparing images for GIS integration. However, pre-processing and flight planning work is often done in other applications and R is used predominantly for processing the mosaiced raster datasets. In this tutorial we are focused on these later steps, especially on nadir/overhead images.</p>
<h2 id="multiple-ways-of-thinking-about-rasters">Multiple ways of thinking about rasters</h2>
<p>Rasters are everywhere including pictures that may or may not have an external coordinate system, medical images (e.g. X-rays), astronomical images from telescopes,  drawings etc. A raster is a grid of cells (or pixels), each holding a value that represents something about the space it covers. These values might describe elevation, temperature, color intensity, or even tissue density—depending on the domain. Some key features:</p>
<ul>
<li>Grid Structure: Rasters are organized into rows and columns, forming a rectangular data.</li>
<li>Pixel Values: Each cell contains a numeric value—this could be brightness, elevation, or a class label.</li>
<li>Resolution: The size of each pixel determines how detailed the raster is. Smaller pixels mean finer detail.</li>
<li>Bands/Layers: Rasters can have multiple layers (bands), each representing different data types (e.g., RGB channels in images). Sometimes, these layers can be discretised time representing the same area at different timestamps.</li>
<li>Spatial Context: Some rasters are tied to real-world coordinates (georeferenced), while others are not. When rasters are georeferenced within a particular coordinate system, all you need to know is the coordinates of the corners of the raster and the resolution to figure out the coordinates of every pixel in the raster.</li>
</ul>
<p>Rasters can be thought of in a number of different ways. Chief among them are:</p>
<ol>
<li>They are similar to rectangular data frames where each pixel is a row and each band is a column. You can have other columns such as raster row position and raster column position.</li>
<li>They are matrices where each cell is a pixel and each band is a matrix.</li>
</ol>
<p>These two points are illustrated below.</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt=""
           src="/post/working-with-drone-imagery/includes/raster_animation.gif"
           loading="lazy" data-zoomable /></div>
  </div></figure>
<!-- --></p>
<ol start="3">
<li>They are a regular network/graph, where each pixel is node and the edges are the connectivity among the pixels; i.e. neighboring pixels are connected to each other. Different connectivities (such as rook, 2-nd order queen) can be defined. This is illustrated below.</li>
</ol>
<img src="includes/raster_graph.png" width="100%" />
<ol start="4">
<li>Rasters are samples of a continuous surface that is discretised by the pixels.</li>
</ol>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt=""
           src="/post/working-with-drone-imagery/includes/raster_continuous_surface.gif"
           loading="lazy" data-zoomable /></div>
  </div></figure>
<!-- --></p>
<p>Each of these ways of thinking may be useful for particular purposes. Sometimes it is helpful to think about rasters with their geographic locations. Sometimes what matters are internal relationships among the pixels.</p>
<h2 id="rasters-in-r">Rasters in R</h2>
<p>R offers a diverse ecosystem of packages for handling rasters, images, and multidimensional arrays across domains like biology, computer vision, remote sensing, and climate science.</p>
<h4 id="remote-sensing--raster-visualization">Remote Sensing &amp; Raster Visualization</h4>
<p>These packages are designed for geospatial raster data, satellite imagery, and thematic mapping.</p>
<table>
<thead>
<tr>
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>terra</strong></td>
<td>Modern package for handling spatial raster data efficiently. Supports cropping, resampling, and projection.</td>
</tr>
<tr>
<td><strong>rasterVis</strong></td>
<td>Enhances raster visualization with lattice-style graphics and thematic mapping tools.</td>
</tr>
<tr>
<td><strong>stars</strong></td>
<td>Handles spatiotemporal arrays and integrates with <code>sf</code> and tidyverse. Great for multi-band satellite data.</td>
</tr>
<tr>
<td><strong>satellite</strong></td>
<td>Tailored for processing satellite imagery, including atmospheric correction and vegetation indices.</td>
</tr>
<tr>
<td><strong>RStoolbox</strong></td>
<td>Toolbox for remote sensing analysis—supports PCA, supervised classification, and spectral indices.</td>
</tr>
</tbody>
</table>
<h4 id="environmental--climate-raster-data">Environmental &amp; Climate Raster Data</h4>
<p>These packages specialize in large-scale environmental datasets, including climate models and ecological predictors.</p>
<table>
<thead>
<tr>
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ncdf4</strong></td>
<td>Low-level interface for reading and writing NetCDF files. Ideal for custom extraction and manipulation.</td>
</tr>
<tr>
<td><strong>RNetCDF</strong></td>
<td>Alternative NetCDF interface with support for metadata and structured arrays.</td>
</tr>
<tr>
<td><strong>stars</strong></td>
<td>Also supports NetCDF and spatiotemporal raster data. Integrates well with tidy workflows.</td>
</tr>
<tr>
<td><strong>geodata</strong></td>
<td>Simplifies access to global environmental datasets like WorldClim, elevation, and land cover.</td>
</tr>
<tr>
<td><strong>elevatr</strong></td>
<td>Easy access to global elevation data from various sources (e.g., SRTM, AWS).</td>
</tr>
<tr>
<td><strong>climate</strong></td>
<td>Tools for analyzing climate data, including temperature and precipitation trends.</td>
</tr>
<tr>
<td><strong>rnoaa</strong></td>
<td>Interfaces with NOAA datasets including climate, weather, and ocean data.</td>
</tr>
</tbody>
</table>
<h4 id="biological--medical-imaging">Biological &amp; Medical Imaging</h4>
<p>These packages are ideal for analyzing microscopy, medical scans, and structural biological data.</p>
<table>
<thead>
<tr>
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>EBImage</strong></td>
<td>Bioconductor package for biological image analysis. Supports segmentation, object detection, and feature extraction.</td>
</tr>
<tr>
<td><strong>mmand</strong></td>
<td>Provides mathematical morphology operations (e.g., erosion, dilation, skeletonization) on multidimensional arrays. Great for structural analysis.</td>
</tr>
<tr>
<td><strong>ANTsR</strong></td>
<td>Advanced image registration and segmentation, especially for neuroimaging. Wraps the ANTs toolkit used in medical research.</td>
</tr>
</tbody>
</table>
<h4 id="general-image-processing--computer-vision">General Image Processing &amp; Computer Vision</h4>
<p>These tools support pixel-level manipulation, filtering, and high-level image editing.</p>
<table>
<thead>
<tr>
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>imager</strong></td>
<td>Versatile for pixel-level operations, filters, edge detection, and convolution. Excellent for computer vision tasks.</td>
</tr>
<tr>
<td><strong>magick</strong></td>
<td>Wraps ImageMagick for high-level image editing—cropping, compositing, format conversion, and annotation.</td>
</tr>
<tr>
<td><strong>OpenImageR</strong></td>
<td>Offers image preprocessing, feature extraction, and similarity metrics. Useful in machine learning pipelines.</td>
</tr>
<tr>
<td><strong>landscapemetrics</strong></td>
<td>Focuses on landscape ecology metrics from raster data. Computes patch, class, and landscape-level statistics.</td>
</tr>
<tr>
<td><strong>imagefx</strong></td>
<td>Lightweight package for basic image effects like blur, sharpen, and color adjustments.</td>
</tr>
</tbody>
</table>
<h2 id="processing-drone-imagery-in-r">Processing Drone Imagery in R</h2>
<p>Let us use <code>terra</code> to process drone imagery in R. Download the <a href="https://www.dropbox.com/scl/fo/zpehjt5qopi21hyua18ha/ALPXxsJ_wzBcIH1gqfXmNMA?rlkey=rynzn7kdzpod6931dv3kqn0k5&amp;dl=0" target="_blank" rel="noopener">required data</a> and locate it into your <code>InputData</code> folder as is the general practise in this class. The following code reads a georeferenced orthomosaic image and visualizes the result.</p>
<pre><code class="language-r">library(terra)

# Adjust the path to where you have stored the data
here(&quot;tutorials_datasets&quot;, &quot;drone_images&quot;, &quot;2_mosaic&quot;, &quot;20240801_Anafi_site4_transparent_mosaic_group1.tif&quot;) %&gt;%
  rast() -&gt; drone_raster

drone_raster
# class       : SpatRaster 
# size        : 11428, 7969, 4  (nrow, ncol, nlyr)
# resolution  : 0.03962, 0.03962  (x, y)
# extent      : 423103.3, 423419.1, 4012352, 4012805  (xmin, xmax, ymin, ymax)
# coord. ref. : WGS 84 / UTM zone 18N (EPSG:32618) 
# source      : 20240801_Anafi_site4_transparent_mosaic_group1.tif 
# names       : 2024080~roup1_1, 2024080~roup1_2, 2024080~roup1_3, 2024080~roup1_4 
# min values  :               0,               0,               0,               0 
# max values  :             255,             255,             255,             255
</code></pre>
<p>Note a few things about the raster:</p>
<ul>
<li>It has 4 bands. It is tempting to think that they are Red, Green, Blue and Near Infrared bands. However, we will see shortly that this is not the case. (Hint: try <code>summary</code>)</li>
<li>The coordinate reference system is UTM zone 18N (EPSG:32618). Thus the units of the raster is in meters</li>
<li>The resolution is about .039 meters (3.9 cm) in both X and Y directions.</li>
<li>The extent of the raster is in UTM coordinates. The lower left corner is at (423103.3, 4012352) and the upper right corner is at (423419.1, 4012805). Thus the raster covers an area of about 316 m by 453 m. This is equivalent to 35 acres.</li>
</ul>
<p>Let&rsquo;s visualise each band separately.</p>
<pre><code class="language-r">par(mfrow = c(2, 2)) # Set up a 2x2 plotting layout

# Loop through and plot the first four bands
for (i in 1:4) {
  plot(drone_raster[[i]],
       main = paste(&quot;Band&quot;, i),
       col = gray.colors(256))
}
</code></pre>
<img src="https://nkaza.github.io/post/working-with-drone-imagery/index.en_files/figure-html/unnamed-chunk-5-1.png" width="960" />
<p>Visualising this suggests that Band 4 is simply a mask that specifies which pixels are valid (non-NA). In this particular instance 255 refers to non-NA values. The other three bands are Red, Green and Blue bands. We can confirm this by plotting a RGB composite image using the <code>plotRGB</code> function.</p>
<pre><code class="language-r">plotRGB(drone_raster, r=1, g=2, b=3,
        stretch=&quot;lin&quot;,
        main=&quot;RGB Composite (1=R, 2=G, 3=B)&quot;)
</code></pre>
<img src="https://nkaza.github.io/post/working-with-drone-imagery/index.en_files/figure-html/unnamed-chunk-6-1.png" width="480" />
<p>It is useful to recognise that the values of the raster can be accessed using the <code>[</code> operator. For example, the value of the pixel at row 1000 and column 500 for bands 1 and 2 can be accessed as follows.</p>
<pre><code class="language-r">drone_raster[1000, 500, 1:2]
#   20240801_Anafi_site4_transparent_mosaic_group1_1
# 1                                               96
#   20240801_Anafi_site4_transparent_mosaic_group1_2
# 1                                              125
</code></pre>
<p>Likewise, <code>[[</code>, or <code>$</code> extracts the entire band as a Spatraster, as we have seen earlier.</p>
<pre><code class="language-r">
drone_raster$`20240801_Anafi_site4_transparent_mosaic_group1_3`
# class       : SpatRaster 
# size        : 11428, 7969, 1  (nrow, ncol, nlyr)
# resolution  : 0.03962, 0.03962  (x, y)
# extent      : 423103.3, 423419.1, 4012352, 4012805  (xmin, xmax, ymin, ymax)
# coord. ref. : WGS 84 / UTM zone 18N (EPSG:32618) 
# source      : 20240801_Anafi_site4_transparent_mosaic_group1.tif 
# name        : 20240801_Anafi_site4_transparent_mosaic_group1_3 
# min value   :                                                0 
# max value   :                                              255

drone_raster[[3]] %&gt;% 
  plot()
</code></pre>
<img src="https://nkaza.github.io/post/working-with-drone-imagery/index.en_files/figure-html/unnamed-chunk-8-1.png" width="672" />
<hr>
<p><strong>Exercise</strong></p>
<ul>
<li>What is the value of the pixel at row 1500 and column 800 for bands 1 and 3?</li>
<li>Extract values for 50x50 pixels starting at row 1200 and column 400 for all three bands.</li>
</ul>
<hr>
<h2 id="raster-arithmetic">Raster Arithmetic</h2>
<p>Raster arithmetic is a powerful technique for deriving new insights from existing raster data. By performing mathematical operations on raster layers, we can create indices that highlight specific features or conditions in the landscape. In this instance, it might be useful to  think of raster layers as columns and the airthmetic is  within each row, with airthmetic happening among the columns (much like most spreadsheet operations, or <code>mutate</code> from tidyverse).</p>
<p>For example,</p>
<p>$$ VARI = \frac{(G - R)}{ (G + R – B)} $$
is particularly good at isolating the vegetation signal by normalizing the Green-Red difference by the overall visible light reflectance.</p>
<pre><code class="language-r">
vari &lt;- (drone_raster[[2]] - drone_raster[[1]]) / 
  (drone_raster[[2]] + drone_raster[[1]] - drone_raster[[3]])

plot(vari, main=&quot;VARI Index&quot;, col=gray.colors(256))
</code></pre>
<img src="https://nkaza.github.io/post/working-with-drone-imagery/index.en_files/figure-html/unnamed-chunk-9-1.png" width="480" />
<hr>
<p><strong>Exercise</strong></p>
<ul>
<li>Other indices that are useful for vegetation include</li>
</ul>
<ol>
<li>Normalized band index (NBI). Each band is normalised by dividing with the sum of all three bands.</li>
<li>Excess green index (ExG). $ 2G - R - B $</li>
<li>Excess green minus excess red index (ExGR). $ 3G - 2.4R - B $</li>
<li>Green leaf index (GLI). $ \frac{2G - R - B}{2G + R + B} $</li>
</ol>
<p>Compute these indices. Visualise the results. Put them in a multilayered SpatRaster object. Which index do you think is best for identifying vegetation in this image? Why?</p>
<ul>
<li>
<p>What happens when the denominator in these indices is 0? How does R handle this? How would you like it to be handled?</p>
</li>
<li>
<p><code>app</code>, <code>lapp</code> are <a href="https://www.pmassicotte.com/posts/2025-06-12-terra-layer-funs/" target="_blank" rel="noopener">useful</a> and memory-safe functions for applying functions to each pixel across multiple layers. Explore these functions and see if you can use them to compute the indices above.</p>
</li>
</ul>
<hr>
<h2 id="colorspaces">Colorspaces</h2>
<p>A color space is a mathematical model for representing colors as a set of numerical values. While the most familiar color space, RGB (Red, Green, Blue), is an additive model that&rsquo;s hardware-oriented, it&rsquo;s not intuitive for humans to manipulate because changing one color channel can unpredictably alter both the hue and brightness.</p>
<p>Hue, which identifies the dominant color and is represented as an angle on a color wheel; Saturation, which denotes the purity or vividness of the color; and Intensity, which represents the overall brightness or luminance. Unlike HSV, which uses the maximum RGB value for its Value component, HSI&rsquo;s Intensity component is often calculated as the average of the red, green, and blue values, making it a more direct measure of brightness.</p>
<pre><code class="language-r">set.RGB(drone_raster, 1:3, &quot;rgb&quot;)
drone_raster_hsi &lt;- colorize(drone_raster, to = &quot;HSI&quot;)

plot(drone_raster_hsi[[1:3]], main=c(&quot;Hue&quot;, &quot;Saturation&quot;, &quot;Intensity&quot;), col=gray.colors(256))
</code></pre>
<img src="https://nkaza.github.io/post/working-with-drone-imagery/index.en_files/figure-html/unnamed-chunk-10-1.png" width="480" />
<h2 id="identifying-glint">Identifying glint</h2>
<p>Glint refers to the bright spots or reflections often seen in aerial imagery, particularly over water bodies or shiny surfaces. These reflections can obscure important details in the image and complicate analysis. Identifying and mitigating glint is crucial for accurate interpretation of drone imagery. In the above image, glint is obvious in various areas in the East and Southwest parts of the image. The glint obscures the submerged aquatic vegetation in these areas.</p>
<p>Let&rsquo;s try a couple of approaches to identify glint in this image.</p>
<p>Areas of glint seem to have high intensity and low saturation. Lets apply some thresholds.</p>
<pre><code class="language-r">
brightness_threshold &lt;- quantile(values(drone_raster_hsi[[3]]), .95, na.rm = TRUE) # High brightness
saturation_threshold &lt;- quantile(values(drone_raster_hsi[[3]]), 0.3, na.rm = TRUE)  # Low saturation
    
glint_mask &lt;- (drone_raster_hsi[[3]] &gt; brightness_threshold) &amp; (drone_raster_hsi[[2]] &lt; saturation_threshold)

plot(glint_mask, main=&quot;Glint Mask (Brightness + Saturation)&quot;)
</code></pre>
<img src="https://nkaza.github.io/post/working-with-drone-imagery/index.en_files/figure-html/unnamed-chunk-11-1.png" width="480" />
<p>Use a relative difference between red and green to identify glint. This is similar to the Normalized Difference Water Index (NDWI) used in remote sensing to identify water bodies.</p>
<pre><code class="language-r">    # Calculate normalized difference water index-like metric
    ndwi &lt;- (drone_raster[[2]] - drone_raster[[1]]) / (drone_raster[[1]] + drone_raster[[2]] + 0.001)  # Add small value to avoid division by zero
  
    ndwi_threshold &lt;- quantile(values(ndwi), 0.7, na.rm = TRUE)
    
    glint_mask2 &lt;- (drone_raster_hsi[[3]] &gt; brightness_threshold) &amp; (ndwi &gt; ndwi_threshold)

    plot(glint_mask2, main=&quot;Glint Mask (NDWI + Intensity)&quot;)
</code></pre>
<img src="https://nkaza.github.io/post/working-with-drone-imagery/index.en_files/figure-html/unnamed-chunk-12-1.png" width="480" />
<hr>
<p><strong>Exercise</strong></p>
<ul>
<li>use Raster arithmetic to substitute for logical arithmetic. In particular, think about how multiplication and addition by 1,0 work? Pay special attention to NAs.</li>
<li>Experiment with different thresholds. How do you think they should be set?</li>
</ul>
<hr>
<p>It might useful to compare the original RGB values among the two glint masks. Note the use of the binary valued glint mask as a row index to extract the RGB values (1:3 columns) from the original raster.</p>
<pre><code class="language-r">
library(cowplot)

rgb_values_glint1 &lt;- as.data.frame(drone_raster)[as.vector(glint_mask), 1:3]
rgb_values_glint2 &lt;- as.data.frame(drone_raster)[as.vector(glint_mask2), 1:3]

names(rgb_values_glint1) &lt;- c(&quot;r&quot;, &quot;g&quot;, &quot;b&quot;)
names(rgb_values_glint2) &lt;- c(&quot;r&quot;, &quot;g&quot;, &quot;b&quot;)

g_red &lt;- ggplot(data =  ) +
  geom_density(aes(x=r, fill=&quot;Mask1&quot;), data = rgb_values_glint1, , alpha=0.5) +
  geom_density(aes(x=r, fill=&quot;Mask2&quot;), data = rgb_values_glint2, alpha=0.5) +
  xlim(0, 255)+
  scale_fill_manual(name=&quot;Glint Mask&quot;, values=c(Mask1=&quot;yellow&quot;, Mask2=&quot;brown&quot;)) +
  theme_minimal() +
  theme(legend.position=&quot;none&quot;) +
  xlab(&quot;Red&quot;) 

g_green &lt;- ggplot(data =  ) +
  geom_density(aes(x=g, fill=&quot;Mask1&quot;), data = rgb_values_glint1, , alpha=0.5) +
  geom_density(aes(x=g, fill=&quot;Mask2&quot;), data = rgb_values_glint2, alpha=0.5) +
  xlim(0, 255)+
  scale_fill_manual(name=&quot;Glint Mask&quot;, values=c(Mask1=&quot;yellow&quot;, Mask2=&quot;brown&quot;)) +
  theme_minimal() +
  theme(legend.position=&quot;none&quot;) +
  xlab(&quot;Green&quot;) 

g_blue &lt;- ggplot(data =  ) +
  geom_density(aes(x=b, fill=&quot;Mask1&quot;), data = rgb_values_glint1, , alpha=0.5) +
  geom_density(aes(x=b, fill=&quot;Mask2&quot;), data = rgb_values_glint2, alpha=0.5) +
  xlim(0, 255)+
  scale_fill_manual(name=&quot;Glint Mask&quot;, values=c(Mask1=&quot;yellow&quot;, Mask2=&quot;brown&quot;)) +
  theme_minimal() +
  theme(legend.position=&quot;none&quot;) +
  xlab(&quot;Blue&quot;)

g_legend &lt;- 
  get_legend(
  g_red + theme(legend.position = &quot;right&quot;)
)

plot_grid(g_red, g_green, g_blue, g_legend, ncol=4, rel_widths = c(1,1,1,.2))
</code></pre>
<img src="https://nkaza.github.io/post/working-with-drone-imagery/index.en_files/figure-html/unnamed-chunk-13-1.png" width="100%" />
<hr>
<p><strong>Exercise</strong></p>
<ul>
<li>Instead of repeating the ggplot for each band, make a function that you can call multiple time and use to generate this graphic.</li>
<li>How might you avoid the use of legends in this graphic? Is it wise?</li>
<li>Figure out an easier wasy to generate this graphic using <code>pivot_longer</code> and <code>facet_grid</code>.</li>
</ul>
<hr>
<h2 id="convolutions--moving-windows">Convolutions &amp; Moving Windows</h2>
<p>Convolutions and moving window operations are fundamental techniques in raster and image processing that apply mathematical operations to each pixel based on its surrounding neighborhood. In these operations, a small matrix called a kernel, filter, or window is systematically moved across the entire raster, with the kernel&rsquo;s center positioned over each target pixel. At each position, the kernel values are multiplied element-wise with the corresponding pixel values in the neighborhood, and these products are summed to produce a new value for the center pixel. This process enables a wide range of analytical capabilities, from simple smoothing and noise reduction using averaging kernels, to edge detection with gradient operators like Sobel or Laplacian filters, to more complex feature extraction and pattern recognition tasks. The size and values within the kernel determine the specific operation performed—for example, a 3×3 kernel filled with 1/9 values creates a mean filter for smoothing, while kernels with positive and negative values can highlight directional edges or enhance specific spatial frequencies. These operations form the mathematical foundation for many advanced techniques in computer vision, remote sensing, and spatial analysis, allowing meaningful information from spatial patterns and relationships within raster datasets to be extracted.</p>
<img src="includes/image_processing_kernels.svg" width="100%" />
<p><img src="includes/gaussian_blur.gif" width="49%" height="20%" style="display: block; margin: auto;" /><img src="includes/highpass_filter.gif" width="49%" height="20%" style="display: block; margin: auto;" /></p>
<pre><code class="language-r">
gaussian_kernel &lt;- matrix(c(
  1, 2, 1,
  2, 4, 2,
  1, 2, 1
), nrow = 3, ncol = 3, byrow = TRUE) / 16


smoothed_intensity &lt;- focal(drone_raster_hsi[[3]], w = gaussian_kernel, fun = sum, na.rm = TRUE)
glint_mask_smooth &lt;- (smoothed_intensity &gt; brightness_threshold) &amp; (drone_raster_hsi[[2]] &lt; saturation_threshold)

plot(glint_mask_smooth , main=&quot;Glint Mask (Smoothed Gaussian + Intensity + Low Saturation) &quot;)
</code></pre>
<img src="https://nkaza.github.io/post/working-with-drone-imagery/index.en_files/figure-html/unnamed-chunk-16-1.png" width="480" />
<hr>
<p><strong>Exercise</strong></p>
<ul>
<li>Try other kernels and see what the output of the convolution is</li>
<li>Explore the effect of changing the size of the kernel</li>
<li>Moving window operations are very similar in concept to &lsquo;rolling&rsquo; operations in time series. Explore the <code>rollapply</code> function from the <code>zoo</code> package and see if can see parallels.</li>
</ul>
<hr>
<p>Morphological operations like erosion and dilation are specialized types of moving window operations that share the same fundamental mechanism as convolutions but operate on binary or grayscale images using set theory principles rather than arithmetic multiplication and summation. In morphological operations, a structural element (analogous to a convolution kernel) moves across the image, but instead of computing weighted sums, these operations apply logical rules based on the spatial relationship between the structural element and the underlying pixel values. Erosion shrinks or &ldquo;erodes&rdquo; bright regions by replacing the center pixel with the minimum value found within the structural element&rsquo;s neighborhood—effectively, a pixel remains bright only if all pixels under the structural element are bright. Conversely, dilation expands bright regions by taking the maximum value in the neighborhood, causing bright areas to grow outward by the shape of the structural element. While convolutions use multiplication and addition to blend neighborhood information, morphological operations use min/max functions or set intersection/union operations, making them particularly effective for shape analysis, noise removal, and boundary extraction in binary images. Both approaches follow the same spatial scanning pattern and neighborhood-based processing philosophy, but morphological operations focus on preserving and manipulating the geometric structure of objects rather than smoothing or detecting gradients.</p>
<img src="includes/morphological_opening.gif" width="100%" />
<p>We can use these morphological operations  to get a better sense of the glint mask by only including areas using <code>focal</code> functions in terra.</p>
<pre><code class="language-r">
struct_elem &lt;- matrix(1, nrow = 5, ncol =5)

glint_eroded &lt;- focal(glint_mask_smooth, w = struct_elem , fun = function(x, ...) as.integer(min(x, na.rm = TRUE)), na.rm = TRUE)
glint_opened &lt;- focal(glint_eroded, w = struct_elem , fun = function(x, ...) as.integer(max(x, na.rm = TRUE)), na.rm = TRUE)

plot(glint_opened, main=&quot;Cleaned Glint Mask (Opening)&quot;)
</code></pre>
<img src="https://nkaza.github.io/post/working-with-drone-imagery/index.en_files/figure-html/unnamed-chunk-18-1.png" width="480" />
<hr>
<p><strong>Exercise</strong></p>
<ul>
<li>Try other morphological operations such as closing, dilation and erosion. How do they compare?</li>
<li>Try other kernels such as cross, diamond, circle etc. How do they compare?</li>
<li>Try other kernel sizes. How do they compare?</li>
</ul>
<hr>
<h2 id="conversion-to-vector">Conversion to vector</h2>
<p>Sometimes, it might be helpful to convert these rasters into vectors for processing elsewhere.</p>
<pre><code class="language-r">
glint_polygons &lt;- as.polygons(glint_opened, dissolve=TRUE)

plot(glint_polygons)
</code></pre>
<img src="https://nkaza.github.io/post/working-with-drone-imagery/index.en_files/figure-html/unnamed-chunk-19-1.png" width="480" />
<p>You can save these as shapefiles, or as other rasters if you prefer</p>
<pre><code class="language-r">writeVector(glint_polygons, here(&quot;outputs&quot;, &quot;glints&quot;), filetype='ESRI Shapefile', insert=FALSE,
    overwrite=FALSE, options=&quot;ENCODING=UTF-8&quot;)

writeRaster(glint_opened, here(&quot;outputs&quot;, 'glint.img'), datatype=&quot;INT1U&quot;)  # Write out the raster in ERDAS Imagine file format, with the right data type (boolean).
</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>In conclusion, basic raster analysis of drone imagery offers a practical framework for understanding urban environments. By processing high-resolution aerial data, analysts can identify spatial patterns such as land use, infrastructure density, and vegetation distribution. However, much of the analysis is about the art of managing large datasets, thinking through analytical frames and bringing to bear other data. We will touch upon these in other tutorials.</p>

      </div>
      <div class="col-12 col-lg-3 docs-toc">
        <ul class="nav toc-top">
          <li>
            <a href="#" id="back_to_top" class="docs-toc-title">
              Contents
            </a>
          </li>
        </ul>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#multiple-ways-of-thinking-about-rasters">Multiple ways of thinking about rasters</a></li>
    <li><a href="#rasters-in-r">Rasters in R</a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#processing-drone-imagery-in-r">Processing Drone Imagery in R</a></li>
    <li><a href="#raster-arithmetic">Raster Arithmetic</a></li>
    <li><a href="#colorspaces">Colorspaces</a></li>
    <li><a href="#identifying-glint">Identifying glint</a></li>
    <li><a href="#convolutions--moving-windows">Convolutions &amp; Moving Windows</a></li>
    <li><a href="#conversion-to-vector">Conversion to vector</a></li>
    <li><a href="#conclusion">Conclusion</a></li>
  </ul>
</nav>
      </div>
    </div>
    








<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://nkaza.github.io/post/working-with-drone-imagery/&amp;text=Working%20with%20Drone%20Imagery" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://nkaza.github.io/post/working-with-drone-imagery/&amp;t=Working%20with%20Drone%20Imagery" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Working%20with%20Drone%20Imagery&amp;body=https://nkaza.github.io/post/working-with-drone-imagery/" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://nkaza.github.io/post/working-with-drone-imagery/&amp;title=Working%20with%20Drone%20Imagery" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=Working%20with%20Drone%20Imagery%20https://nkaza.github.io/post/working-with-drone-imagery/" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://nkaza.github.io/post/working-with-drone-imagery/&amp;title=Working%20with%20Drone%20Imagery" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://nkaza.github.io/"><img class="avatar mr-3 avatar-circle" src="/author/nikhil-kaza/avatar_hub3f48de923d36a3a7f2a35d484d2e93d_2804906_270x270_fill_q75_lanczos_center.jpg" alt="Nikhil Kaza"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://nkaza.github.io/">Nikhil Kaza</a></h5>
      <h6 class="card-subtitle">Professor</h6>
      <p class="card-text">My research interests include urbanization patterns, local energy policy and equity</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=F0FfN00AAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/nkaza" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://orcid.org/0000-0002-9536-7643" target="_blank" rel="noopener">
        <i class="ai ai-orcid"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/nikhilkaza/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>
















  
  




  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  



  

  
  <p class="powered-by">
    
      <a href="/privacy/">Privacy Policy</a>
    
    
  </p>
  

  
  <p class="powered-by">
    © 2018-2025 Nikhil Kaza
  </p>
  

  
  





  
  
  
  

  
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    Except as otherwise noted, this work is licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0" rel="noopener noreferrer" target="_blank">CC BY SA 4.0</a>, and code samples are licensed under the MIT License.
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-sa/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-sa fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>




  <p class="powered-by">
    
    
    
  </p>
</footer>

    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    <script src="/js/vendor-bundle.min.b73dfaac3b6499dc997741748a7c3fe2.js"></script>

    
    
    
      
      
        <script src="https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js" integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js" integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin="anonymous"></script>
      

      
      

      

      
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js" integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin="anonymous"></script>
        
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js" crossorigin="anonymous"></script>
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/python.min.js" crossorigin="anonymous"></script>
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/latex.min.js" crossorigin="anonymous"></script>
        
      

    

    
    
    
      <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    
      
      
      
      
      
      
      
    

    

    
    
    
    <script id="page-data" type="application/json">{"use_headroom":true}</script>

    
    
      <script src="/js/wowchemy-headroom.1cb9e2fc8399acee94eab837265b73bf.js" type="module"></script>
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.247fd8f54253895301106e3006f53f38.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
