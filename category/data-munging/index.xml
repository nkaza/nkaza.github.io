<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data-munging | Nikhil Kaza</title>
    <link>https://nkaza.github.io/category/data-munging/</link>
      <atom:link href="https://nkaza.github.io/category/data-munging/index.xml" rel="self" type="application/rss+xml" />
    <description>data-munging</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2018-2023 Nikhil Kaza</copyright><lastBuildDate>Thu, 31 Jul 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://nkaza.github.io/media/icon_hu1ca6a6912ef6c300619228a995d3f134_46128_512x512_fill_lanczos_center_3.png</url>
      <title>data-munging</title>
      <link>https://nkaza.github.io/category/data-munging/</link>
    </image>
    
    <item>
      <title>Possibilities and Pitfalls of Large Language Models.</title>
      <link>https://nkaza.github.io/post/possibilities-and-pitfalls-of-large-language-models/</link>
      <pubDate>Thu, 31 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://nkaza.github.io/post/possibilities-and-pitfalls-of-large-language-models/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This post was last updated on 2025-08-07&lt;/p&gt;
&lt;p&gt;Large Language Models (LLMs) represent a class of artificial intelligence systems that have fundamentally transformed natural language processing and generation. These neural networks, trained on vast corpora of text data, demonstrate remarkable capabilities in mimicking the understanding context, generating coherent(ish) responses, and performing complex reasoning tasks across diverse domains.&lt;/p&gt;
&lt;p&gt;At their core, most modern LLMs are built upon the &lt;strong&gt;transformer architecture&lt;/strong&gt;, introduced in the seminal paper &lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34;&gt;“Attention Is All You Need”&lt;/a&gt; by Vaswani et al. in 2017. The transformer’s key innovation lies in its self-attention mechanism, which allows the model to weigh the importance of different words in a sequence when processing each token. This parallel processing capability offers significant computational advantages over previous sequential architectures like RNNs and LSTMs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/Transformers.png&#34; /&gt;
(Generated by Gemini)&lt;/p&gt;
&lt;p&gt;The transformer consists of encoder and decoder blocks, each containing multi-head self-attention layers and feed-forward networks. However, most contemporary LLMs adopt variations of this base architecture, leading to distinct model families with different strengths and applications.&lt;/p&gt;
&lt;p&gt;LLM development typically follows a multi-stage process. &lt;strong&gt;Pre-training&lt;/strong&gt; involves unsupervised learning on massive text corpora, where models learn to predict next tokens and develop broad linguistic understanding. This is why many of the models are really bad at langauges other than English. &lt;strong&gt;Fine-tuning&lt;/strong&gt; adapts pre-trained models to specific tasks or domains through supervised learning on curated datasets.&lt;/p&gt;
&lt;div id=&#34;architectural-variations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Architectural Variations&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Encoder-only models&lt;/strong&gt;, such as &lt;a href=&#34;https://arxiv.org/abs/1810.04805&#34;&gt;BERT&lt;/a&gt; (Bidirectional Encoder Representations from Transformers), excel at understanding and encoding text representations. These models process input bidirectionally, making them particularly effective for tasks like sentiment analysis, question answering, and text classification where understanding context from both directions is crucial.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Decoder-only models&lt;/strong&gt; represent the dominant paradigm for generative LLMs. Models like &lt;a href=&#34;https://openai.com/research/language-unsupervised&#34;&gt;GPT&lt;/a&gt; (Generative Pre-trained Transformer), &lt;a href=&#34;https://www.anthropic.com/claude&#34;&gt;Claude&lt;/a&gt;, and &lt;a href=&#34;https://arxiv.org/abs/2302.13971&#34;&gt;LLaMA&lt;/a&gt; use causal self-attention, processing text autoregressively from left to right. This architecture proves highly effective for text generation, completion, and conversational AI applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Encoder-decoder models&lt;/strong&gt;, including &lt;a href=&#34;https://arxiv.org/abs/1910.10683&#34;&gt;T5&lt;/a&gt; (Text-to-Text Transfer Transformer) and &lt;a href=&#34;https://arxiv.org/abs/1910.13461&#34;&gt;BART&lt;/a&gt;, combine both components and excel at sequence-to-sequence tasks like translation, summarization, and text transformation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scale-and-emergent-capabilities&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Scale and Emergent Capabilities&lt;/h3&gt;
&lt;p&gt;The “large” in Large Language Models refers to their unprecedented scale across multiple dimensions: parameter count, training data volume, and computational requirements. Modern LLMs contain billions to trillions of parameters, with models like &lt;a href=&#34;https://arxiv.org/abs/2303.08774&#34;&gt;GPT-4&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2204.02311&#34;&gt;PaLM&lt;/a&gt; demonstrating that increased scale often leads to emergent capabilities not present in smaller models.&lt;/p&gt;
&lt;p&gt;These emergent properties include where models can adapt to new tasks with minimal examples, chain-of-thought reasoning for complex problem-solving, and cross-modal understanding when trained on multimodal data. The scaling hypothesis, which I do not subscribe to, suggests that many AI capabilities may emerge naturally from increased model size and training data, though this relationship isn’t always predictable.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;use-case&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Use Case&lt;/h2&gt;
&lt;p&gt;LLMs have found applications across a wide range of domains and in particular for planning purposes they can be used for extracting data from unstructured texts. In this tutorial, I am going to demonstrate it on an example dataset scraped from the &lt;a href=&#34;https://starw1.ncuc.gov/NCUC/page/Dockets/portal.aspx&#34;&gt;North Carolina Utilities Commission website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;“Pursuant to G.S. 62-110.1(g), any person who seeks to construct an electric generating facility in North Carolina, and is exempt from the requirement to obtain a certificate of public convenience and necessity, is required to file this [ROPC] form and a notice of completion of the construction of the facility.”&lt;/p&gt;
&lt;p&gt;Small scale (&amp;lt;1 MW) solar power plants (rooftop or ground mounted) fall under this category. This &lt;a href=&#34;https://www.dropbox.com/scl/fi/nreu2frrsqw1soqbk1y6b/dockets_fileurls_unique.csv?rlkey=xz3xa33c8he5es3qd1hdkk5fn&amp;amp;dl=0&#34;&gt;dataset&lt;/a&gt; consists of all the unique records for ROPC until mid May 2024. Note that these do not necessarily mean that the plant is completed or operational.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(here)

ropc_data &amp;lt;- here(&amp;quot;tutorials_datasets&amp;quot;, &amp;quot;llms&amp;quot;, &amp;quot;dockets_fileurls_unique.csv&amp;quot;) %&amp;gt;%
  read_csv(show_col_types = FALSE) %&amp;gt;%
  mutate(across(everything(), as.character))

set.seed(123)  # For reproducibility
test_data &amp;lt;- ropc_data %&amp;gt;%
  sample_n(5)

test_data$Description
# [1] &amp;quot;ROPC for 0.00609MW Solar Located at 7145 Streamhaven Drive, Harrisburg, NC 28075 in Cabarrus County\nFiles:&amp;quot;
# [2] &amp;quot;ROPC for 5.2kW Solar Located at 179 Lars Lane, Garner, NC 27529 in Johnston County\nFiles:&amp;quot;                 
# [3] &amp;quot;ROPC for 10.85kW Solar System Located at 8804 Amerjack Ct. Raleigh, NC 27603 in Wake County\nFiles:&amp;quot;        
# [4] &amp;quot;ROPC for 10.88 kW Solar Located at 46 Sunnyfield Ct Benson NC 27504 in Johnston County\nFiles:&amp;quot;             
# [5] &amp;quot;Amended ROPC\nFiles:&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that the description column in the dataset contains unstructured text that describes the solar power plant including the street address information that can be used for &lt;a href=&#34;https://nkaza.github.io/post/matching-messy-texts/&#34;&gt;geocoding&lt;/a&gt;. The goal is to extract structured information from this text using a Large Language Model (LLM). We will first try to do this with an Open Source and free model called &lt;a href=&#34;https://ollama.com/&#34;&gt;Ollama&lt;/a&gt; and then with a commercial model called &lt;a href=&#34;https://www.anthropic.com/claude&#34;&gt;Anthropic’s Claude&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;using-local-llms&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using Local LLMs&lt;/h3&gt;
&lt;p&gt;Ollama is a platform that allows you to run large language models locally on your machine. It provides a simple command-line interface to download and run models, making it easy to experiment with LLMs without needing an internet connection or API keys.&lt;/p&gt;
&lt;p&gt;To use Ollama, you need to install it on your machine. You can find installation instructions on the &lt;a href=&#34;https://ollama.com/docs/installation&#34;&gt;Ollama website&lt;/a&gt;. Once installed and running, you can download models using the &lt;code&gt;ollmar&lt;/code&gt; package. For example, to download the &lt;code&gt;Llama 3.2 model&lt;/code&gt;, you would run:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ollamar)
ollamar::pull(&amp;quot;llama3.2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can see all the models you have downloaded locally by using &lt;code&gt;list_models()&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ollamar::list_models()
#              name    size parameter_size quantization_level            modified
# 1 llama3.1:latest  4.9 GB           8.0B             Q4_K_M 2025-07-30T13:43:47
# 2 llama3.2:latest    2 GB           3.2B             Q4_K_M 2025-07-30T14:02:07
# 3 llama3.3:latest 42.5 GB          70.6B             Q4_K_M 2025-07-30T13:33:53&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Notice that llama 3.3 is substantially larger than llama 3.2, and thus requires more memory to run.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Once the model is downloaded, you can interact with it using the &lt;code&gt;ellmer&lt;/code&gt; package in R. The &lt;code&gt;ellmer&lt;/code&gt; package provides a convenient interface for interacting with various LLMs, including both open-source and commercial models. It allows you to send prompts to the models and receive structured responses.&lt;/p&gt;
&lt;p&gt;First initialise the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ellmer)
library(jsonlite)

ollama_chat &amp;lt;- chat_ollama(
  model = &amp;quot;llama3.2&amp;quot;,
  system_prompt = &amp;quot;You are an expert at extracting structured information from unstructured text. Always return valid JSON.&amp;quot;,
)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;prompt-engineering&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Prompt Engineering&lt;/h3&gt;
&lt;p&gt;Prompt engineering has emerged as a critical skill for effectively leveraging LLMs, involving the strategic design and refinement of input instructions to elicit desired model behaviours and outputs. The quality and structure of prompts significantly influence model performance.&lt;/p&gt;
&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/7wizt0K4EBA&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Key rules of thumb:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Be explicit and specific in your instructions rather than relying on implicit understanding&lt;/li&gt;
&lt;li&gt;Provide concrete examples of desired outputs when possible (few-shot prompting)&lt;/li&gt;
&lt;li&gt;Breaking complex tasks into smaller, sequential steps to enable clearer reasoning.&lt;/li&gt;
&lt;li&gt;Assign specific roles or personas when relevant (“act as a data scientist analysing…”), and iterate on your prompts based on initial outputs.&lt;/li&gt;
&lt;li&gt;Test your prompts across different scenarios and edge cases to ensure robustness, as small changes in wording can sometimes produce dramatically different results from the same model.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
extraction_prompt &amp;lt;- &amp;quot;
Extract the following information from the given text and return ONLY valid JSON, no markdown:

{
  \&amp;quot;street_address\&amp;quot;: \&amp;quot;extracted street address or null\&amp;quot;,
  \&amp;quot;city\&amp;quot;: \&amp;quot;extracted city or null\&amp;quot;, 
  \&amp;quot;state\&amp;quot;: \&amp;quot;extracted state abbreviation or null\&amp;quot;,
  \&amp;quot;zip_code\&amp;quot;: \&amp;quot;extracted ZIP code or null\&amp;quot;,
  \&amp;quot;capacity\&amp;quot;: \&amp;quot;extracted capacity along with power units in W, kiloWatts (KW), MegaWatts (MW) or null. \&amp;quot;
  \&amp;quot;type\&amp;quot;: \&amp;quot;AC or DC or null\&amp;quot;

}

Rules:
- Only extract information that is clearly present
- Return null for missing information. Do not make up values
- Ensure valid JSON format
- No text outside the JSON response

Text to analyze: &amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s try and extract data for one of the records in the dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
full_prompt &amp;lt;- paste0(extraction_prompt, test_data$Description[1])


response &amp;lt;- tryCatch({
    ollama_chat$chat(full_prompt, echo = FALSE)
  }, error = function(e) {
    message(&amp;quot;Error: &amp;quot;, e$message)
    return(NULL)
  })


  parsed_response &amp;lt;- tryCatch({
    fromJSON(response) %&amp;gt;% 
      map(~ ifelse(is.null(.x), NA, .x))
  }, error = function(e) {
    list(street_address = NA, city = NA, state = NA, zip_code = NA, capacity = NA, type = NA)
  }) %&amp;gt;%
    as_tibble()
  
print(cbind(Docket_Name = test_data$Docket_Name[1], parsed_response))
#                            Docket_Name         street_address       city state
# 1 a2527260-ba3c-48a4-b511-75cd95455530 7145 Streamhaven Drive Harrisburg    NC
#   zip_code capacity type
# 1    28075       NA   AC&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rerun this code multiple times and see if you get the same results. If not, why do you think that is?&lt;/li&gt;
&lt;li&gt;Re-engineer the prompt to extract the capacity in kiloWatts (kW) only and perform any necessary conversions.&lt;/li&gt;
&lt;li&gt;Figure out why is it necessary to convert the NULLs to NAs. What happens when you don’t?&lt;/li&gt;
&lt;li&gt;Change the model to Llama 3.1 and see if you get the same results. If not, why do you think that is? What about Llama 3.3? Does it work? If not, why do you think that is?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;It is more straightforward to extract structured information using &lt;code&gt;ellmer&lt;/code&gt; without resorting to &lt;code&gt;jsonlite&lt;/code&gt;. But first we need to define the structure of the data we want to extract. This is done using the &lt;code&gt;type_object&lt;/code&gt; function from &lt;code&gt;ellmer&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
type_solar &amp;lt;- type_object(street_address = type_string(required = FALSE), city = type_string(required = FALSE), 
                          state = type_string(&amp;quot;2 letter US state abbreviation&amp;quot;, required = FALSE), zip_code = type_string(&amp;quot;5 digit US ZIP code&amp;quot;, required = FALSE), 
                          capacity = type_string(&amp;quot;in any power units such as W, KW or MW&amp;quot;, required = FALSE), capacity_type = type_string(&amp;quot;AC or DC&amp;quot;, required = FALSE))


ollama_chat$chat_structured(full_prompt, type = type_solar) %&amp;gt;%
  as_tibble() %&amp;gt;%
  print()
# # A tibble: 1 × 6
#   street_address         city       state zip_code capacity capacity_type
#   &amp;lt;chr&amp;gt;                  &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;        
# 1 7145 Streamhaven Drive Harrisburg NC    28075    &amp;quot;&amp;quot;       DC&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;/p&gt;
&lt;p&gt;Note that the model does not recognise the &lt;code&gt;capacity_type&lt;/code&gt; as AC or DC. It does not understand the notion of types of electricity and their designations. In the previous code chunks, it hallucinated the value as AC, even though the text did not specify it and we explictly asked it not to hallucinate. This is a &lt;em&gt;very&lt;/em&gt; common problem with LLMs. You should treat the output from LLMs with extreme caution.&lt;/p&gt;
&lt;p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt;
* Rewrite the code to extract the data for 100 random records in the dataset. How long does it take?&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;commercial-models&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Commercial Models&lt;/h3&gt;
&lt;p&gt;To use commercial LLMs such as Claude or GPT, you need to acquire API keys from the respective providers. These models often provide more advanced capabilities and better performance than open-source models, but they come with associated costs. You can set the API key in your R environment using the &lt;code&gt;Sys.setenv()&lt;/code&gt; function. For example, to set the API key for Anthropic’s Claude, you would do:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Sys.setenv(ANTHROPIC_API_KEY = &amp;quot;.......&amp;quot;) # Replace with your actual API key&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    &lt;/p&gt;
&lt;p&gt;Commercial LLMs such as Claude, and GPT require you to pay for them. Please acquire your own API keys. You should expect to pay for the API calls you make. Thus, this post only uses very small dataset. Expect to spend some money if you want to follow along.&lt;/p&gt;
&lt;p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;The process then in very similar to using Ollama. You first need to initialise the model with the &lt;code&gt;ellmer&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;claude_chat &amp;lt;- chat_anthropic(
  model = &amp;quot;claude-3-5-sonnet-20241022&amp;quot;,  # or &amp;quot;claude-3-opus-20240229&amp;quot;, &amp;quot;claude-3-haiku-20240307&amp;quot;
  api_key = Sys.getenv(&amp;quot;ANTHROPIC_API_KEY&amp;quot;),
  system_prompt = &amp;quot;You are an expert at extracting structured information from unstructured text. Always return valid JSON.&amp;quot;,
  params = list(max_tokens = 1000,temperature = 0.1)  # Low temperature for consistent extraction
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fortunately, with Claude you can do batch processing of prompts, which is very useful for large datasets. The &lt;code&gt;batch_chat_structured&lt;/code&gt; function allows you to send multiple prompts at once and receive structured responses in a single call.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prompts_ropc &amp;lt;- map(test_data$Description, function(s){paste0(extraction_prompt, s)})

batch_chat_structured(claude_chat, 
                      prompts_ropc, 
                      wait = TRUE, 
                      type = type_solar, 
                      path = &amp;#39;solar.json&amp;#39;, 
                      include_cost = TRUE)

# Description:df [5 × 7]
# street_address	city	state	zip_code	capacity	capacity_type	cost
# 7145 Streamhaven Drive	Harrisburg	NC	28075	0.00609MW	NA	0.003840
# 179 Lars Lane	Garner	NC	27529	5.2KW	NA	0.003759
# 8804 Amerjack Ct	Raleigh	NC	27603	10.85KW	NA	0.003870
# 46 Sunnyfield Ct	Benson	NC	27504	10.88 kW	NA	0.003843
# NA	NA	NA	NA	NA	NA	0.003201
5 rows
&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Compare the differences in the output between Ollama and Claude. Can you generalise?&lt;/li&gt;
&lt;li&gt;Try a different model like chat_mistral() or chat_gemini() and see if you get the same results. If not, why do you think that is?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;more-complicated-chunks&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;More complicated chunks&lt;/h3&gt;
&lt;p&gt;There is no reason to presume that LLMs can only read and interpret simple texts. You can use to extract structured information from more complicated texts such as tables, or even pdfs with varying degrees of efficiency. Let’s try Llama on a small subset of &lt;a href=&#34;https://www.dropbox.com/scl/fo/7phnvvdbwwxkfkqz7vdk5/AApenea-EDXSWnQ1uk7zZRU?rlkey=fj2izokc8c0g9c7nnql8altpk&amp;amp;dl=0&#34;&gt;pdfs&lt;/a&gt; that include actual ROPC submissions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paths = here(&amp;quot;tutorials_datasets&amp;quot;, &amp;quot;llms&amp;quot;, &amp;quot;pdfs&amp;quot;) %&amp;gt;%
  list.files(full.names = T)

extraction_prompt3 &amp;lt;- &amp;quot;
Extract the following information in each of the pdf files and return ONLY valid JSON, no markdown:

{
  \&amp;quot;owner_type\&amp;quot;: \&amp;quot;Individual or Corportation or Partnership or null\&amp;quot;,
  \&amp;quot;agent\&amp;quot;: \&amp;quot;extracted agent name or null\&amp;quot;,
  \&amp;quot;agent_business_address\&amp;quot;: \&amp;quot;extracted address or null\&amp;quot;, 
  \&amp;quot;site_address\&amp;quot;: \&amp;quot;extracted E911 street address or null\&amp;quot;,
  \&amp;quot;gps_coords\&amp;quot;: \&amp;quot;GPS coordinates or null\&amp;quot;,
  \&amp;quot;capacity\&amp;quot;: \&amp;quot;extracted capacity along with power units in W, kiloWatts (KW), MegaWatts (MW) or null. \&amp;quot;
  \&amp;quot;annual_sales\&amp;quot;: \&amp;quot;extracted projected annual sales or null\&amp;quot;

}

Rules:
- Only extract information that is clearly present
- Return null for missing information. Do not make up values
- Ensure valid JSON format
- Be thorough - check the entire document for relevant information
&amp;quot;

claude_chat$chat(extraction_prompt3, content_pdf_file(paths[1]), echo =FALSE) %&amp;gt;%
                   fromJSON() %&amp;gt;%
                        map(~ ifelse(is.null(.x), NA, .x)) %&amp;gt;%
                   as_tibble()

# # A tibble: 1 × 7
#  owner_type agent                agent_business_address             site_address gps_coords capacity annual_sales
#  &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;                &amp;lt;chr&amp;gt;                              &amp;lt;chr&amp;gt;        &amp;lt;lgl&amp;gt;      &amp;lt;chr&amp;gt;    &amp;lt;lgl&amp;gt;       
#1 Individual Nexus Energy Systems 10964 Richardson Road, Ashland, V… 101 Bunker … NA         4.93 kW… NA    
&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do this for all the pdfs in the folder. How long does it take? How much does it cost?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The emergence of LLMs has fundamentally transformed the landscape of data extraction from unstructured sources. Where traditional approaches relied on rigid patterns, complex rules, and brittle parsing logic, LLMs bring contextual understanding, semantic awareness, and remarkable adaptability to the challenge of converting messy, real-world text into clean, actionable data.&lt;/p&gt;
&lt;p&gt;However, these are not without challenges. The non-deterministic nature of LLMs means that outputs may vary between runs, requiring careful validation and quality control processes. This poses serious problems for reproducibility. In addition, costs can accumulate quickly with large-scale operations, particularly when using cloud-based APIs. Privacy and security concerns demand thoughtful consideration, especially when processing sensitive documents. And while LLMs are remarkably capable, they are not infallible—human oversight remains essential for critical applications.&lt;/p&gt;
&lt;p&gt;The most successful implementations combine the strengths of LLMs with complementary technologies: using traditional preprocessing to clean and structure input data, implementing robust validation pipelines to catch errors, and designing human-in-the-loop workflows for quality assurance.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Matching Messy Texts</title>
      <link>https://nkaza.github.io/post/matching-messy-texts/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://nkaza.github.io/post/matching-messy-texts/</guid>
      <description>&lt;h1 id=&#34;the-problems-of-free-form-text&#34;&gt;The Problems of Free Form Text&lt;/h1&gt;
&lt;p&gt;One of the joys of language is that there is an infinite variety of ways in which we can express ourselves. Conventions vary. People are likely to run afoul of grammatical and spelling conventions depending on their background, attention to detail and adherence to convention. This expressive variety becomes a disadvantage for a data analyst who wants to analyse text. Urban datasets frequently contain free form language; names, addresses, surveys, regulations, complaints, tweets, posts, newspaper reports, plans, interviews, ordinances etc. When the text is not standardised and restricted, they pose problems for a data analyst who is trying to reduce and distill the information, often ignoring the context and conventions that the gives meaning to the text. The text is then wrangled, standardised or ignored. In this blog, I will show how one might attempt to wrangle text. I also want to highlight the decisions that the analyst makes that severely distort the meaning and introduce errors.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;All clean datasets are alike. But each messy dataset is messy in its own way &amp;mdash; Prener paraphrasing Wickham paraprhasing Tolstoy&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;data--required-packages&#34;&gt;Data &amp;amp; Required Packages&lt;/h1&gt;
&lt;p&gt;The Worker Adjustment and Retraining Notification Act (WARN) requires employers with 100 or more employees (generally not counting those who have worked less than six months in the last 12 months and those who work an average of less than 20 hours a week) to provide at least 60 calendar days advance written notice of a plant closing and mass lay-off affecting 50 or more employees at a single site of employment. In North Carolina, the Department of Commerce is in charge of collecting and archiving the notices.  &lt;a href=&#34;https://www.clevelandfed.org/~/media/content/newsroom%20and%20events/publications/working%20papers/2020/wp2003.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Research&lt;/a&gt; by Cleveland Federal Reserve Bank suggests that these notices are useful bellwethers for economic conditions in the state.&lt;/p&gt;
&lt;p&gt;In this blog, I am going to use another business listings dataset from Infogroup called &lt;a href=&#34;http://resource.referenceusa.com/available-databases/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ReferenceUSA&lt;/a&gt; to establish additional information about the business that is listed in the WARN database. We are limiting &lt;a href=&#34;https://www.dropbox.com/sh/a3eyf8n0u1ynqfn/AADM7S8ufQxlA3W_Y_m_bGmxa?dl=0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;our analysis to Mecklenberg county&lt;/a&gt; in North Carolina. ReferenceUSA data for the US can be obtained from UNC library. I obtained the WARN dataset from Cleveland Federal Reserve. Citation for the data is&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Krolikowski, Pawel M. and Kurt G. Lunsford. 2020. “Advance Layoff Notices and Labor Market Forecasting.” Federal Reserve Bank of Cleveland, Working Paper no. 20-03. &lt;a href=&#34;https://doi.org/10.26509/frbc-wp-202003&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.26509/frbc-wp-202003&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this tutorial, I am going to use &lt;code&gt;stringr&lt;/code&gt;, &lt;code&gt;stringdist&lt;/code&gt;, &lt;code&gt;postmastr&lt;/code&gt; and &lt;code&gt;censusxy&lt;/code&gt; packages in addition to other packages in R. &lt;code&gt;postmastr&lt;/code&gt; is not yet available on CRAN, but can be installed from github using&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;remotes::install_github(&amp;quot;slu-openGIS/postmastr&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    At the time of writing, postmastr is still in beta stages. So it may be buggy. Use it with caution.
  &lt;/div&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)
library(skimr)

warn &amp;lt;- 
  here(&amp;quot;tutorials_datasets&amp;quot;, &amp;quot;textmatching&amp;quot;, &amp;quot;WARN_Mecklenburg.csv&amp;quot;) %&amp;gt;% 
  read_csv()

names(warn)
#  [1] &amp;quot;county&amp;quot;          &amp;quot;notice_date&amp;quot;     &amp;quot;received_date&amp;quot;   &amp;quot;effective_date&amp;quot; 
#  [5] &amp;quot;company&amp;quot;         &amp;quot;type&amp;quot;            &amp;quot;number_affected&amp;quot; &amp;quot;zipcode_city&amp;quot;   
#  [9] &amp;quot;warn_no&amp;quot;         &amp;quot;address&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;parsing-the-addresses&#34;&gt;Parsing the Addresses&lt;/h1&gt;
&lt;p&gt;Most geocoders expect an address that is properly standardised (e.g. South - S, Bvld - Boulevard ) and spelling errors corrected. This is important as user entered text about addresses rely on personal and local convention rather than standardisation.&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    The following sections refer to addresses within the US, following its conventions. While some of the methods will transfer to other locations, use caution to interpret and adapt .
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;postmastr works by following the &lt;em&gt;precise sequence&lt;/em&gt; of the following steps.&lt;/p&gt;
&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;
&lt;p&gt;First there is a need to create a unique ID for unique addresses, so that only unique addresses are parsed.
A quick look at the address column reveals that it has newlines &lt;code&gt;\n&lt;/code&gt; in some of the entries. Let&amp;rsquo;s replace it with a space. We are going to use &lt;a href=&#34;https://rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Regular Expressions&lt;/a&gt; to search and replace.&lt;/p&gt;
&lt;p&gt;In the following code, I am replacing all the diacritics, e.g.ř, ü, é, è by transliterating to Latin alphabet. This is not strictly necessary but is useful to remember that some place names are in Spanish in the US. Some databases store the diacritics and some don&amp;rsquo;t. Apologies to speakers of other languages.&lt;/p&gt;
&lt;p&gt;It is always a good idea to have one case. We are going to use the upper case.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;warn &amp;lt;- warn %&amp;gt;%
        mutate(address = str_replace_all(address, &amp;quot;[[:space:]]&amp;quot;, &amp;quot; &amp;quot;),
               address = stringi::stri_trans_general(address, &amp;quot;Latin-ASCII&amp;quot;),
               address = str_remove_all(address, &amp;quot;[[:punct:]]&amp;quot;),
               address = str_to_upper(address)
               
               ) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(postmastr)
warn &amp;lt;- pm_identify(warn, var = &amp;quot;address&amp;quot;)
warn_min &amp;lt;- pm_prep(warn, var = &amp;quot;address&amp;quot;, type =&#39;street&#39;) # There do not seem to be any addresses that are based on intersections. So we are using the type=street.
nrow(warn)
# [1] 111
nrow(warn_min)
# [1] 91
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should notice the difference in the number of rows. 20 observations are dropped.&lt;/p&gt;
&lt;h2 id=&#34;extract-zipcodes-and-states&#34;&gt;Extract Zipcodes and States&lt;/h2&gt;
&lt;p&gt;Zipcodes come in two formats. A 5 digit variety and 5-4 digit variety. &lt;code&gt;pm_postal_parse&lt;/code&gt; is able to parse both types, though in this instance only 5 digit codes are present.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;warn_min &amp;lt;- pm_postal_parse(warn_min)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this instance only state present in the dataset is NC. First we need to create a dictonary in case NC is spelled out in different ways such as NORTH CAROLINA or NC or N CAROLINA. Fortunately, this dataset only contains NC. If not, use &lt;code&gt;pm_append&lt;/code&gt; to add different instances of the state name to the dictionary.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ncDict &amp;lt;- pm_dictionary(locale = &amp;quot;us&amp;quot;, type = &amp;quot;state&amp;quot;, filter = &amp;quot;NC&amp;quot;, case = &amp;quot;upper&amp;quot;)
ncDict
# # A tibble: 2 × 2
#   state.output state.input   
#   &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;         
# 1 NC           NC            
# 2 NC           NORTH CAROLINA

(warn_min &amp;lt;- pm_state_parse(warn_min, dict=ncDict))
# # A tibble: 91 × 4
#    pm.uid pm.address                          pm.state pm.zip
#     &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;                               &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt; 
#  1      1 895 WEST TRADE STREET CHARLOTTE     NC       28202 
#  2      2 5501 JOSH BIRMINGAHM PKWY CHARLOTTE NC       28208 
#  3      3 4800 HANGAR ROAD CHARLOTTE          NC       28208 
#  4      4 5020 HANGAR ROAD CHARLOTTE          NC       28208 
#  5      5 4716 YORKMONT ROAD CHARLOTTE        NC       28208 
#  6      6 5501 JOSH BIRMINGHAM PKWY CHARLOTTE NC       28208 
#  7      7 5000 HANGAR ROAD CHARLOTTE          NC       28208 
#  8      8 100 WEST TRADE STREET CHARLOTTE     NC       28202 
#  9      9 5501 CARNEGIE BLVD CHARLOTTE        NC       28209 
# 10     10 2200 REXFORD ROAD CHARLOTTE         NC       28211 
# # … with 81 more rows
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ncCityDict &amp;lt;- pm_dictionary(locale = &amp;quot;us&amp;quot;, type = &amp;quot;city&amp;quot;, filter = &amp;quot;NC&amp;quot;, case = &amp;quot;upper&amp;quot;)
(warn_min &amp;lt;- pm_city_parse(warn_min, dictionary = ncCityDict))
# # A tibble: 91 × 5
#    pm.uid pm.address                pm.city   pm.state pm.zip
#     &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;                     &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt; 
#  1      1 895 WEST TRADE STREET     CHARLOTTE NC       28202 
#  2      2 5501 JOSH BIRMINGAHM PKWY CHARLOTTE NC       28208 
#  3      3 4800 HANGAR ROAD          CHARLOTTE NC       28208 
#  4      4 5020 HANGAR ROAD          CHARLOTTE NC       28208 
#  5      5 4716 YORKMONT ROAD        CHARLOTTE NC       28208 
#  6      6 5501 JOSH BIRMINGHAM PKWY CHARLOTTE NC       28208 
#  7      7 5000 HANGAR ROAD          CHARLOTTE NC       28208 
#  8      8 100 WEST TRADE STREET     CHARLOTTE NC       28202 
#  9      9 5501 CARNEGIE BLVD        CHARLOTTE NC       28209 
# 10     10 2200 REXFORD ROAD         CHARLOTTE NC       28211 
# # … with 81 more rows
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;parsing-street-numbers-and-direction&#34;&gt;Parsing Street, Numbers and Direction&lt;/h2&gt;
&lt;p&gt;We can use similar functions to parse out the street number.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;warn_min &amp;lt;- warn_min %&amp;gt;%
             pm_house_parse()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Directionality of the street is little of a challenge. North could mean direction or a street name North St. Postmastr has logic already built into it to distinguish these two cases.  By default, postmastr uses dic_us_dir dictionary.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dic_us_dir
# # A tibble: 20 × 2
#    dir.output dir.input 
#    &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;     
#  1 E          E         
#  2 E          East      
#  3 N          N         
#  4 N          North     
#  5 NE         NE        
#  6 NE         Northeast 
#  7 NE         North East
#  8 NW         NW        
#  9 NW         Northwest 
# 10 NW         North West
# 11 S          S         
# 12 S          South     
# 13 SE         SE        
# 14 SE         Southeast 
# 15 SE         South East
# 16 SW         SW        
# 17 SW         Southwest 
# 18 SW         South West
# 19 W          W         
# 20 W          West
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have already converted our strings to upper cases rather than leaving it in the sentence case as dic_us_dir assumes. We will have to modify the dictionary to fit our useccase.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dic_us_dir &amp;lt;- dic_us_dir %&amp;gt;%
              mutate(dir.input = str_to_upper(dir.input))


warn_min &amp;lt;- warn_min %&amp;gt;%  
             pm_streetDir_parse(dictionary = dic_us_dir) %&amp;gt;%
             pm_streetSuf_parse() %&amp;gt;%
             pm_street_parse(ordinal = TRUE, drop = TRUE)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have parsed data, we add our parsed data back into the source.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;warn_parsed &amp;lt;- pm_replace(warn_min, source = warn) %&amp;gt;%
               pm_rebuild(output=&amp;quot;short&amp;quot;, keep_parsed = &#39;yes&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that it is straightforward to geocode the addresses using a census geocoder. You can quickly visualise using mapview.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(censusxy)

warn_sf &amp;lt;- cxy_geocode(warn_parsed, street = &amp;quot;pm.address&amp;quot;, city = &amp;quot;pm.city&amp;quot;, state = &amp;quot;pm.state&amp;quot;, zip = &amp;quot;pm.zip&amp;quot;,
    output = &amp;quot;full&amp;quot;, class = &amp;quot;sf&amp;quot;, parallel = 4) # You can only use parallel on non-Windows OS and must specify the number of cores that you want to employ for this exercise

library(tmap)
tmap_mode(&#39;view&#39;)

m1 &amp;lt;-
tm_shape(warn_sf)+
  tm_symbols(col =&#39;red&#39;) + 
  tm_basemap(leaflet::providers$Stamen.TonerHybrid)
  
library(widgetframe)
frameWidget(tmap_leaflet(m1))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that only 75 of the unique 90 addresses are geocoded by the geocoder. Using other geocoders in combination might improve the hit rate.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;API calls are notoriously fickle. So this creates a replicability problem. However, you could also do this part locally.  Download the &lt;a href=&#34;https://www.nconemap.gov/datasets/nc-master-address-dataset-2014?showData=true&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;master list of addresses for North Carolina&lt;/a&gt; and match the latitude and longitude with the parsed address fields in the two datasets.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Instead of &lt;code&gt;censusxy&lt;/code&gt; geocoder package, try &lt;code&gt;tidygeocoder&lt;/code&gt;. See if you can improve the hitrate using multiple geocoding services.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;matching-names&#34;&gt;Matching Names&lt;/h2&gt;
&lt;p&gt;Notice that in WARN data there are no NAICS codes. So it is hard to tell which industry is being affected by these layoffs. Fortunately, another dataset has names and NAICS codes. So just as we matched parsed addresses to latitude an longitude, we can try and match names to NAICS codes. However, names are more idiosyncratic than addresses.&lt;/p&gt;
&lt;p&gt;Here are some rules, I came up using iterative methods. They are not exhaustive nor are they representative of what you might want to with other datasets.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;

# I am trying to remove common words in the name that can impact string similarity scores. Add to the list or modify to suit.

removalwords &amp;lt;- c(&amp;quot;CORP&amp;quot;, &amp;quot;CORPORATION&amp;quot;, &amp;quot;SERVICE&amp;quot;, &amp;quot;SERVICES&amp;quot;, &amp;quot;CO&amp;quot;,  &amp;quot;GROUP&amp;quot;, &amp;quot;HOLDINGS&amp;quot;, &amp;quot;MANAGEMENT&amp;quot;, &amp;quot;LTD&amp;quot;, &amp;quot;INC&amp;quot;, &amp;quot;LLC&amp;quot;, &amp;quot;PC&amp;quot;, &amp;quot;PLLC&amp;quot;, &amp;quot;SOLUTIONS&amp;quot;, &amp;quot;COMPANY&amp;quot;, &amp;quot;COMPANIES&amp;quot;, &amp;quot;MANAGEMENT&amp;quot;, &amp;quot;MGMNT&amp;quot;)

placenames &amp;lt;- tigris::places(state=&amp;quot;NC&amp;quot;, progress_bar = FALSE) %&amp;gt;% sf::st_set_geometry(NULL) %&amp;gt;% pull(NAME) %&amp;gt;% toupper()


compnames &amp;lt;- warn_parsed %&amp;gt;%
  select(company, pm.zip) %&amp;gt;%
  mutate(
    orig_company = company,
    company = str_squish(company),  # Removes leading and trailing white spaces
    company = str_remove_all(company, &amp;quot;\\&amp;amp;[A-Za-z]*;&amp;quot;), # This removes some HTML tags like &amp;amp;quot; &amp;amp;lt; etc.
    company = str_remove_all(company, &amp;quot;COVID19&amp;quot;), # Removes a special tag
    company = str_remove_all(company, &amp;quot;\\t|\\n|\\r&amp;quot;),  # This removes newlines and some other returns
    company = str_remove_all(company, &amp;quot;[[:punct:]]&amp;quot;), # This removes punctuations marks such as `,`, `&#39;`, &#39;?
    company = str_replace_all(company, &amp;quot;\\.&amp;quot;, &amp;quot;\ &amp;quot;), # This replaces . with a space.
    company = str_replace(company, &amp;quot;\\D\\B\\A&amp;quot;, &amp;quot;DBA&amp;quot;), #This replaces \D\B\A with DBA
    company = str_replace_all(company, &amp;quot;\\&amp;lt;U\\+0082\\&amp;gt;&amp;quot;, &amp;quot;E&amp;quot;), #This unicode character &amp;lt;U+0082&amp;gt; is usually meant to be an e in cafes.
    company = str_to_upper(company), # Convert to upper case.
    company = str_remove_all(company, paste0(&amp;quot;\\b(&amp;quot;,paste0(removalwords,  collapse=&amp;quot;|&amp;quot;), &amp;quot;)\\b&amp;quot;)), # Remove all the words that are in the list above.
   company = str_remove_all(company, paste0(&amp;quot;\\b(&amp;quot;,paste0(placenames,  collapse=&amp;quot;|&amp;quot;), &amp;quot;)\\b&amp;quot;)), # Remove place names from the company names. This may not work out well if the company is called for e.g. Charlotte Plastics.
    name1 = str_split(company, &amp;quot;DBA&amp;quot;, n=2, simplify = T)[,1] %&amp;gt;% str_squish(), #The following two lines split the names of the company at DBA (Doing Business As).
    name2 = str_split(company, &amp;quot;DBA&amp;quot;, n=2, simplify = T)[,2] %&amp;gt;% str_squish()
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can make educated guesses about what the NAICS codes for the WARN dataset are going to by searching for some common substrings associated with the industry. For example, sector 72 is Accommodation and Food Services.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;compnames &amp;lt;- compnames %&amp;gt;%
  mutate(NAICS2 = case_when(
    str_detect(company, &amp;quot;\\bMEDICAl\\b&amp;quot;) ~ &amp;quot;62&amp;quot;,
    str_detect(company, &#39;\\bAIRLINES\\b&#39;) ~ &amp;quot;48&amp;quot;,
    str_detect(company, &#39;\\bRESTAURANT|RSTRNT\\b&#39;) ~ &amp;quot;72&amp;quot;,
    str_detect(company, &#39;\\bCAFE|BAR\\b&#39;) ~ &amp;quot;72&amp;quot;,
    str_detect(company, &amp;quot;\\bFITNESS\\b&amp;quot;) ~ &amp;quot;71&amp;quot;,
    TRUE ~ NA_character_
    
  )
  )

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We still need to find out the NAICS code for 85 companies.&lt;/p&gt;
&lt;h3 id=&#34;fuzzy-string-matching&#34;&gt;Fuzzy String Matching&lt;/h3&gt;
&lt;p&gt;For the rest of the dataset, we are going to use Reference USA dataset that has names and NAICS codes.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;refUSA &amp;lt;- here(&amp;quot;tutorials_datasets&amp;quot;, &amp;quot;textmatching&amp;quot;, &amp;quot;2019_Mecklenburg_RefUSA.csv&amp;quot;) %&amp;gt;% read_csv() %&amp;gt;%
  mutate(orig_company = company,
         company = str_to_upper(company),
         company = str_remove_all(company, &amp;quot;[[:punct:]]&amp;quot;),
         company = str_replace_all(company, &amp;quot;\\.&amp;quot;, &amp;quot;\ &amp;quot;),
         company = str_remove_all(company, paste0(&amp;quot;\\b(&amp;quot;,paste0(removalwords,  collapse=&amp;quot;|&amp;quot;), &amp;quot;)\\b&amp;quot;)),
         company = str_squish(company)
  ) %&amp;gt;%
  mutate(NAICS2 = str_sub(primary_naics, start=1, end=2)) %&amp;gt;%
  filter(company != &amp;quot;&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Try matching (exact) on names from the WARN dataset to the RefUSA dataset. What is the match rate?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;You will notice that the match rate is on exact match is not great because of various spellings and typos. Thus asking the question what is the row that matches the company name string in RefUSA dataset. So we instead ask a different question. How similar are two strings?  To do that we have to understand the notion of distance between two strings. There are number of such distances. Here are some common ones.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Levenshtein distance (lv) the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other&lt;/li&gt;
&lt;li&gt;Damerau–Levenshtein (dl) distance is the minimum number of operations (consisting of insertions, deletions or substitutions of a single character, or &lt;em&gt;transposition&lt;/em&gt; of two adjacent characters) required to change one word into the other.&lt;/li&gt;
&lt;li&gt;Optimal String Alignment (osa) uses Damerau–Levenshtein distance but each substring may only be edited once.&lt;/li&gt;
&lt;li&gt;Hamming distance (hamming) is the number of positions with same symbol/character in both strings of equal length.&lt;/li&gt;
&lt;li&gt;Longest common substring distance (lcs) is the minimum number of symbols/characters that need to be removed to make the two strings the same.&lt;/li&gt;
&lt;li&gt;Jaro-winker distance (jw) is a distance that is derived from the lengths of two strings, number of shared symbols an their transpositions.&lt;/li&gt;
&lt;li&gt;soundex is distance between two strings when they are translated to phonetic code.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are by no means exhaustive. They can even be improved upon (e.g. weighting spelling errors based on keyboard layouts.)&lt;/p&gt;
&lt;p&gt;In the following code, I am going to use a bunch of different string distance algorithms, find the most similar string based on each algorithm and pick the string that is selected by many different algorithms.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This is by no means the only way to do this fuzzy matching or even the most appropriate way. I am demonstrating this here for pedagogical purposes. You should explore alternatives.
  &lt;/div&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(stringdist)

distance_methods&amp;lt;-c(&#39;osa&#39;, &#39;dl&#39;,&#39;lcs&#39;,&#39;jw&#39;, &#39;soundex&#39;)

# While loops are terrible in R it is easy to program them. Better for readability.

for (i in 1:dim(compnames)[1]){
  # Only focus on the subset of data that we did not already hard code the NAICS
  if(is.na(compnames$NAICS2[i])){
    company &amp;lt;- compnames[i,]
    name1 &amp;lt;- company$name1
    name2 &amp;lt;- company$name2
    zcta &amp;lt;- company$pm.zip
    
    # Create a target dataset.
    refusa_select &amp;lt;- refUSA %&amp;gt;% filter(zip_code == zcta)
    
    # The following creates a vector of potential candidates (best match based on different algorithms)
    # In the following, I am using similarity score of 0.75 or higher. Adjust this for tighter or looser matches.
    
    closestmatch &amp;lt;-
      map_int(distance_methods,  # for each distance method
              possibly(
                function(x){
                  name1sim &amp;lt;- stringsim(name1, refusa_select$company, method= x) # Create a string similarity between name1 and refusa name
                  name2sim &amp;lt;- stringsim(name2, refusa_select$company, method=x)  # Create a string similarity between name2 and refusa name
                  # Apply a threshold
                  name1sim &amp;lt;- ifelse(name1sim&amp;lt;0.75, NA, name1sim)
                  name2sim &amp;lt;- ifelse(name2sim&amp;lt;0.75, NA, name2sim)
                  # Between name1sim an name2sim, pick the one with the highest score.
                  k &amp;lt;- pmax(name1sim, name2sim, na.rm=T) %&amp;gt;% which.max()
                  return(ifelse(length(k)!=0,k,NA_integer_))
                },
                NA_integer_
              )
      ) %&amp;gt;%
      .[!is.na(.)]
    
    # Of the distance methods, only select the matches that pass the threshold and pick the NAICS code that has the highest frequency. Note that this code does not break ties.i.e. there may be multiple NAICS that potentially picked by multiple algorithms, but this code picks the one that is at the top (possibly ordered)
    
    
    compnames$NAICS2[i]&amp;lt;- 
      ifelse(length(closestmatch)&amp;gt;0, 
               refusa_select[closestmatch,] %&amp;gt;%
               group_by(NAICS2) %&amp;gt;%
               summarize(no = n()) %&amp;gt;%
               slice_max(no, n=1, with_ties = FALSE) %&amp;gt;% select(NAICS2) %&amp;gt;% unlist() %&amp;gt;% unname(),
             NA_character_
      )
    
    rm(name1,name2,zcta,closestmatch)
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of the  111 we are able to determine the NAICS codes for 87 companies, a 78.38 % hit rate. This seems reasonable, for short amount of work.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use a different set string distance algorithms, esp ones based on n-grams.&lt;/li&gt;
&lt;li&gt;Instead of selecting strings with maximum similarity, select top 5 similar strings and then pick the string that appears in most of these algorithms.&lt;/li&gt;
&lt;li&gt;What other preprocessing can be done to improve the hit rate?&lt;/li&gt;
&lt;li&gt;Spot check to see if the hits are accurate?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;As you noticed, a lot of text/string manipulation relies on understanding the linguistic conventions and is an iterative processes. What works in one context may not work in another and you should be prepared to adapt. You will encounter edge cases much more frequently in this type of work, than other kinds of data munging operations. Nonetheless, it is a useful skill to have. In particular, it is useful get familiar with using &lt;a href=&#34;https://www.regexbuddy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Regular Expressions&lt;/a&gt; to search for patterns within strings. However, use it judiciously.&lt;/p&gt;
&lt;h2 id=&#34;additional-resources&#34;&gt;Additional Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Silge, Julia, and David Robinson. 2020. Text Mining with R. Sebastapol, CA: O’ Reilly. &lt;a href=&#34;https://www.tidytextmining.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.tidytextmining.com/&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
